import numpy as np

def mse_loss(beta, X, y):
    predictions = X @ beta
    return np.mean((predictions - y) ** 2)

def grad_mse_loss(beta, X, y):
    predictions = X @ beta
    return (2 / X.shape[0]) * X.T @ (predictions - y)

def S(i):
    def constraint(y):
        return y
    return constraint

def aam(f, grad_f, S, x0, v0):
    A0 = 0
    x = x0
    v = v0
    A = A0
    a = 1.0
    max_iter=100
    tol=1e-6
    
    for k in range(max_iter):
        beta_set = np.linspace(0, 1, 100)
        beta_values = [f(x + beta * (v - x)) for beta in beta_set]
        beta = beta_set[np.argmin(beta_values)]
        y = x + beta * (v - x)
        grad_y = grad_f(y)
        i = np.argmax([np.linalg.norm(grad_y[j]) ** 2 for j in range(grad_y.shape[0])])
        x_set = [S(i)(y)]
        x_values = [f(x_candidate) for x_candidate in x_set]
        x_next = x_set[np.argmin(x_values)]
        A_next = A + a
        a_next = a
        while f(y) - (a_next ** 2) / (2 * A_next) * np.linalg.norm(grad_y) ** 2 > f(x_next):
            a_next *= 0.5
        
        x = x_next
        v = v - a_next * grad_y
        A = A_next
        a = a_next
        
        if np.linalg.norm(grad_y) < tol:
            break
    
    return x


np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

X_b = np.c_[np.ones((100, 1)), X] #intercept

beta0 = np.random.randn(2, 1)
v0 = np.random.randn(2, 1)

result = aam(lambda beta: mse_loss(beta, X_b, y), lambda beta: grad_mse_loss(beta, X_b, y), S, beta0, v0)
print("Optimized beta:", result)
